{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit requests pydub transformers pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn_opcAforWG",
        "outputId": "26249495-4579-445a-aeb4-ae458916b3a5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5crog_krwtp",
        "outputId": "14699bd6-737e-4964-e9df-a75f803db856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-10 12:09:50.844 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-10 12:09:50.847 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-10 12:09:50.848 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-10 12:09:50.849 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-10 12:09:50.850 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-10 12:09:50.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-10 12:09:50.853 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-10 12:09:50.854 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-10 12:09:50.855 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-10 12:09:50.856 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import streamlit as st\n",
        "import requests\n",
        "from pydub import AudioSegment\n",
        "import io\n",
        "\n",
        "# Configuration\n",
        "SARVAM_AI_API_KEY = \"35215873-d423-44c0-89ea-5e2550ce057f\"\n",
        "API_URL = \"https://api.sarvam.ai/speech-to-text\"\n",
        "\n",
        "st.set_page_config(page_title=\" Sarvam Speech-to-Text\", layout=\"centered\")\n",
        "st.title(\"🎧 Sarvam AI Speech-to-Text\")\n",
        "st.markdown(\"Upload multiple audio files (`.wav`, `.mp3`) and transcribe them in English using Sarvam AI's STT API.\")\n",
        "\n",
        "uploaded_files = st.file_uploader(\" Upload Audio Files\", type=[\"wav\", \"mp3\"], accept_multiple_files=True)\n",
        "\n",
        "# Fix language and model to English\n",
        "language = \"en-IN\"\n",
        "model = \"saarika:v2\"\n",
        "\n",
        "def transcribe_audio(audio_bytes, lang=\"en-IN\", model_name=\"saarika:v2\"):\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(io.BytesIO(audio_bytes))\n",
        "        buffer = io.BytesIO()\n",
        "        audio.export(buffer, format=\"wav\")\n",
        "        buffer.seek(0)\n",
        "    except Exception as e:\n",
        "        st.error(f\"❌ Audio conversion error: {e}\")\n",
        "        return None\n",
        "\n",
        "    headers = {\n",
        "        \"api-subscription-key\": SARVAM_AI_API_KEY\n",
        "    }\n",
        "    data = {\n",
        "        \"language_code\": lang,\n",
        "        \"model\": model_name,\n",
        "        \"with_timestamps\": False\n",
        "    }\n",
        "    files = {\"file\": (\"audio.wav\", buffer, \"audio/wav\")}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(API_URL, headers=headers, data=data, files=files)\n",
        "        if response.status_code in [200, 201]:\n",
        "            return response.json().get(\"transcript\", \" No transcript found.\")\n",
        "        else:\n",
        "            st.error(f\" API Error {response.status_code}: {response.text}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        st.error(f\" Request failed: {e}\")\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "\n",
        "def map_sentiment(score, label):\n",
        "    if label.lower() == \"positive\":\n",
        "        if score >= 0.95:\n",
        "            return \"excellent\"\n",
        "        elif score >= 0.85:\n",
        "            return \"good\"\n",
        "        else:\n",
        "            return \"decent\"\n",
        "    elif label.lower() == \"negative\":\n",
        "        if score >= 0.95:\n",
        "            return \"horrible\"\n",
        "        elif score >= 0.85:\n",
        "            return \"very bad\"\n",
        "        else:\n",
        "            return \"bad\"\n",
        "    return \"neutral\"\n",
        "\n",
        "\n",
        "def chunk_text(text, max_length=512):\n",
        "    sentences = text.split(\". \")\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk) + len(sentence) < max_length:\n",
        "            current_chunk += sentence + \". \"\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \". \"\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "    return chunks\n",
        "\n",
        "# Main sentiment function\n",
        "def extract_sentiment(text, return_chunks=False):\n",
        "    if not text.strip():\n",
        "        return {\n",
        "            \"label\": \"neutral\",\n",
        "            \"original_label\": \"neutral\",\n",
        "            \"polarity\": 0.0\n",
        "        }\n",
        "\n",
        "    chunks = chunk_text(text)\n",
        "    results = sentiment_pipeline(chunks)\n",
        "\n",
        "     sentiment scores\n",
        "    pos_scores = []\n",
        "    neg_scores = []\n",
        "    mapped_labels = []\n",
        "\n",
        "    for res in results:\n",
        "        label = res['label']\n",
        "        score = res['score']\n",
        "        mapped = map_sentiment(score, label)\n",
        "        mapped_labels.append(mapped)\n",
        "\n",
        "        if label.lower() == \"positive\":\n",
        "            pos_scores.append(score)\n",
        "        elif label.lower() == \"negative\":\n",
        "            neg_scores.append(score)\n",
        "\n",
        "    # Final decision\n",
        "    avg_pos = np.mean(pos_scores) if pos_scores else 0\n",
        "    avg_neg = np.mean(neg_scores) if neg_scores else 0\n",
        "\n",
        "    if avg_pos > avg_neg:\n",
        "        overall_label = \"positive\"\n",
        "        polarity = avg_pos\n",
        "    elif avg_neg > avg_pos:\n",
        "        overall_label = \"negative\"\n",
        "        polarity = avg_neg\n",
        "    else:\n",
        "        overall_label = \"neutral\"\n",
        "        polarity = 0.0\n",
        "\n",
        "    final_sentiment = map_sentiment(polarity, overall_label)\n",
        "\n",
        "    result = {\n",
        "        \"label\": final_sentiment,\n",
        "        \"original_label\": overall_label,\n",
        "        \"polarity\": polarity\n",
        "    }\n",
        "\n",
        "    if return_chunks:\n",
        "        result[\"chunk_sentiments\"] = [\n",
        "            {\n",
        "                \"text\": chunk,\n",
        "                \"raw\": res,\n",
        "                \"mapped_label\": map_sentiment(res['score'], res['label'])\n",
        "            }\n",
        "            for chunk, res in zip(chunks, results)\n",
        "        ]\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCKzRkxj7SFU",
        "outputId": "be42eae6-5c30-4fa9-e39d-568249f633fb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SENTIMENT ANALYSIS OF THE CALL TRANSCRIPT\n"
      ],
      "metadata": {
        "id": "MVVU-s34ssRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, actually I want to cancel the order. The behavior of the delivery boy was very rude and the quality of the product was also not good. So I will like to cancel the order and very pathetic and horrible service from Flipkart and I didn't expect this. No, no, no, I will cancel the order. You guys have become too worse. Yes, keep a look, keep a look.\"\n",
        "\n",
        "\n",
        "\n",
        "sentiment = extract_sentiment(text, return_chunks=True)\n",
        "print(sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOdHdGuSzkwL",
        "outputId": "34bec0e0-ef55-4267-8991-b43030fea064"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 'horrible', 'original_label': 'negative', 'polarity': np.float64(0.9997701048851013), 'chunk_sentiments': [{'text': \"Hello, actually I want to cancel the order. The behavior of the delivery boy was very rude and the quality of the product was also not good. So I will like to cancel the order and very pathetic and horrible service from Flipkart and I didn't expect this. No, no, no, I will cancel the order. You guys have become too worse. Yes, keep a look, keep a look..\", 'raw': {'label': 'NEGATIVE', 'score': 0.9997701048851013}, 'mapped_label': 'horrible'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAGGING THE TRANSCRIPT ON THE BASIS OF ISSUE OR QUERY\n"
      ],
      "metadata": {
        "id": "yFDxCrSMs7g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers faiss-cpu --quiet\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "# 1. Define your fixed tags and example sentences (including new tags)\n",
        "fixed_tags_examples = {\n",
        "    \"return\": [\n",
        "        \"I want to return my order.\",\n",
        "        \"How can I send the product back?\",\n",
        "        \"The item arrived damaged, I need to return it.\",\n",
        "        \"Can I get a refund for a return?\",\n",
        "        \"I initiated a return request yesterday.\",\n",
        "        \"Return shipping costs are confusing.\",\n",
        "        \"Product return was not accepted.\",\n",
        "        \"Returned the product but no update on refund.\",\n",
        "        \"How long does a return take?\",\n",
        "        \"I changed my mind and want to return.\"\n",
        "    ],\n",
        "    \"payment\": [\n",
        "        \"My payment failed at checkout.\",\n",
        "        \"There was a problem with my credit card.\",\n",
        "        \"How do I update my payment method?\",\n",
        "        \"Payment confirmation not received.\",\n",
        "        \"I was charged twice for one order.\",\n",
        "        \"Transaction got declined unexpectedly.\",\n",
        "        \"Can I get help with payment errors?\",\n",
        "        \"Payment gateway is not working.\",\n",
        "        \"Refund hasn't been processed to my account.\",\n",
        "        \"I want to change payment to cash on delivery.\"\n",
        "    ],\n",
        "    \"delivery\": [\n",
        "        \"My order hasn't arrived yet.\",\n",
        "        \"Where is my package?\",\n",
        "        \"Delivery was late by 3 days.\",\n",
        "        \"The delivery address was incorrect.\",\n",
        "        \"Can I reschedule my delivery?\",\n",
        "        \"Package got lost during shipping.\",\n",
        "        \"Received the wrong item in delivery.\",\n",
        "        \"Delivery person was not able to contact me.\",\n",
        "        \"How to track my shipment?\",\n",
        "        \"The parcel was damaged upon delivery.\"\n",
        "    ],\n",
        "    \"quality_issue\": [\n",
        "        \"The product quality is poor.\",\n",
        "        \"I received a defective item.\",\n",
        "        \"The material feels cheap and fragile.\",\n",
        "        \"Product stopped working after a week.\",\n",
        "        \"There are scratches on the surface.\",\n",
        "        \"The color is different from what was advertised.\",\n",
        "        \"The size does not match the description.\",\n",
        "        \"It broke during first use.\",\n",
        "        \"The stitching on the clothes is coming apart.\",\n",
        "        \"I am not satisfied with the build quality.\"\n",
        "    ],\n",
        "    \"behavior_issue\": [\n",
        "        \"The delivery person was rude.\",\n",
        "        \"Customer service was unhelpful.\",\n",
        "        \"The agent raised their voice at me.\",\n",
        "        \"I faced rude behavior during the call.\",\n",
        "        \"Support team was not respectful.\",\n",
        "        \"The representative ignored my questions.\",\n",
        "        \"I had a bad experience with the sales staff.\",\n",
        "        \"The service agent was impatient.\",\n",
        "        \"They didn't follow up as promised.\",\n",
        "        \"I felt disrespected by the support team.\"\n",
        "    ],\n",
        "    \"important_issue\": [\n",
        "        \"My account was hacked.\",\n",
        "        \"I lost access to my account.\",\n",
        "        \"Important payment failed without notification.\",\n",
        "        \"There is a security breach in my profile.\",\n",
        "        \"Urgent: I need immediate help with my order.\",\n",
        "        \"Critical issue with the product delivery.\",\n",
        "        \"The app crashed and lost all my data.\",\n",
        "        \"I was billed incorrectly, need urgent resolution.\",\n",
        "        \"My personal data was leaked.\",\n",
        "        \"Please escalate this complaint urgently.\"\n",
        "    ],\n",
        "    \"technical_issue\": [\n",
        "        \"The website is not loading.\",\n",
        "        \"App keeps crashing on startup.\",\n",
        "        \"I cannot login to my account.\",\n",
        "        \"Payment gateway throws an error.\",\n",
        "        \"The search function is broken.\",\n",
        "        \"I experience frequent disconnections.\",\n",
        "        \"Error message appears when submitting form.\",\n",
        "        \"Notifications are not working.\",\n",
        "        \"The page layout is messed up on mobile.\",\n",
        "        \"Video playback is buffering constantly.\"\n",
        "    ],\n",
        "    \"account_issue\": [\n",
        "        \"I need to update my profile details.\",\n",
        "        \"How do I reset my password?\",\n",
        "        \"My account was suspended without reason.\",\n",
        "        \"I want to close my account.\",\n",
        "        \"There is a problem with my account verification.\",\n",
        "        \"I cannot access premium features.\",\n",
        "        \"My account shows wrong order history.\",\n",
        "        \"I did not receive the account confirmation email.\",\n",
        "        \"Account login fails despite correct credentials.\",\n",
        "        \"I want to link my account to social media.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 2. Load sentence transformer model\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# 3. Compute averaged embeddings for each tag\n",
        "tag_names = []\n",
        "tag_embeddings = []\n",
        "\n",
        "for tag, examples in fixed_tags_examples.items():\n",
        "    embeddings = embedder.encode(examples)\n",
        "    avg_embedding = np.mean(embeddings, axis=0)\n",
        "    tag_names.append(tag)\n",
        "    tag_embeddings.append(avg_embedding)\n",
        "\n",
        "tag_embeddings = np.vstack(tag_embeddings).astype('float32')\n",
        "\n",
        "# 4. Build FAISS index\n",
        "dimension = tag_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 distance\n",
        "index.add(tag_embeddings)\n",
        "\n",
        "print(f\"FAISS index built with {index.ntotal} tags.\")\n",
        "\n",
        "# 5. Define function to find top-k matching tags for a transcript\n",
        "def tag_transcript(transcript, top_k=3):\n",
        "    transcript_emb = embedder.encode([transcript]).astype('float32')\n",
        "    distances, indices = index.search(transcript_emb, top_k)\n",
        "    results = []\n",
        "    for dist, idx in zip(distances[0], indices[0]):\n",
        "        tag = tag_names[idx]\n",
        "        score = 1 / (1 + dist)  # convert L2 dist to similarity-like score\n",
        "        results.append((tag, score))\n",
        "    return results\n",
        "\n",
        "# --- Example usage ---\n",
        "sample_text = \"Hello, this is Shriyank, I am talking to Flipkart. Yeah, my order hasn't been delivered for two days. No, I had already contacted the seller, but it has still not been delivered. Please look forward to the issues. Yes, yes.\"\n",
        "matches = tag_transcript(sample_text)\n",
        "\n",
        "print(\"Top matching tags:\")\n",
        "for tag, score in matches:\n",
        "    print(f\"- {tag} (score: {score:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYh5mWVV-kVu",
        "outputId": "e25de63b-0363-42d4-cb4c-d13a326c7233"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index built with 8 tags.\n",
            "Top matching tags:\n",
            "- delivery (score: 0.6222)\n",
            "- important_issue (score: 0.5432)\n",
            "- return (score: 0.5369)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit_code = \"\"\"\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "# 1. Define your fixed tags and example sentences (including new tags)\n",
        "fixed_tags_examples = {\n",
        "    \"return\": [\n",
        "        \"I want to return my order.\",\n",
        "        \"How can I send the product back?\",\n",
        "        \"The item arrived damaged, I need to return it.\",\n",
        "        \"Can I get a refund for a return?\",\n",
        "        \"I initiated a return request yesterday.\",\n",
        "        \"Return shipping costs are confusing.\",\n",
        "        \"Product return was not accepted.\",\n",
        "        \"Returned the product but no update on refund.\",\n",
        "        \"How long does a return take?\",\n",
        "        \"I changed my mind and want to return.\"\n",
        "    ],\n",
        "    \"payment\": [\n",
        "        \"My payment failed at checkout.\",\n",
        "        \"There was a problem with my credit card.\",\n",
        "        \"How do I update my payment method?\",\n",
        "        \"Payment confirmation not received.\",\n",
        "        \"I was charged twice for one order.\",\n",
        "        \"Transaction got declined unexpectedly.\",\n",
        "        \"Can I get help with payment errors?\",\n",
        "        \"Payment gateway is not working.\",\n",
        "        \"Refund hasn't been processed to my account.\",\n",
        "        \"I want to change payment to cash on delivery.\"\n",
        "    ],\n",
        "    \"delivery\": [\n",
        "        \"My order hasn't arrived yet.\",\n",
        "        \"Where is my package?\",\n",
        "        \"Delivery was late by 3 days.\",\n",
        "        \"The delivery address was incorrect.\",\n",
        "        \"Can I reschedule my delivery?\",\n",
        "        \"Package got lost during shipping.\",\n",
        "        \"Received the wrong item in delivery.\",\n",
        "        \"Delivery person was not able to contact me.\",\n",
        "        \"How to track my shipment?\",\n",
        "        \"The parcel was damaged upon delivery.\"\n",
        "    ],\n",
        "    \"quality_issue\": [\n",
        "        \"The product quality is poor.\",\n",
        "        \"I received a defective item.\",\n",
        "        \"The material feels cheap and fragile.\",\n",
        "        \"Product stopped working after a week.\",\n",
        "        \"There are scratches on the surface.\",\n",
        "        \"The color is different from what was advertised.\",\n",
        "        \"The size does not match the description.\",\n",
        "        \"It broke during first use.\",\n",
        "        \"The stitching on the clothes is coming apart.\",\n",
        "        \"I am not satisfied with the build quality.\"\n",
        "    ],\n",
        "    \"behavior_issue\": [\n",
        "        \"The delivery person was rude.\",\n",
        "        \"Customer service was unhelpful.\",\n",
        "        \"The agent raised their voice at me.\",\n",
        "        \"I faced rude behavior during the call.\",\n",
        "        \"Support team was not respectful.\",\n",
        "        \"The representative ignored my questions.\",\n",
        "        \"I had a bad experience with the sales staff.\",\n",
        "        \"The service agent was impatient.\",\n",
        "        \"They didn't follow up as promised.\",\n",
        "        \"I felt disrespected by the support team.\"\n",
        "    ],\n",
        "    \"important_issue\": [\n",
        "        \"My account was hacked.\",\n",
        "        \"I lost access to my account.\",\n",
        "        \"Important payment failed without notification.\",\n",
        "        \"There is a security breach in my profile.\",\n",
        "        \"Urgent: I need immediate help with my order.\",\n",
        "        \"Critical issue with the product delivery.\",\n",
        "        \"The app crashed and lost all my data.\",\n",
        "        \"I was billed incorrectly, need urgent resolution.\",\n",
        "        \"My personal data was leaked.\",\n",
        "        \"Please escalate this complaint urgently.\"\n",
        "    ],\n",
        "    \"technical_issue\": [\n",
        "        \"The website is not loading.\",\n",
        "        \"App keeps crashing on startup.\",\n",
        "        \"I cannot login to my account.\",\n",
        "        \"Payment gateway throws an error.\",\n",
        "        \"The search function is broken.\",\n",
        "        \"I experience frequent disconnections.\",\n",
        "        \"Error message appears when submitting form.\",\n",
        "        \"Notifications are not working.\",\n",
        "        \"The page layout is messed up on mobile.\",\n",
        "        \"Video playback is buffering constantly.\"\n",
        "    ],\n",
        "    \"account_issue\": [\n",
        "        \"I need to update my profile details.\",\n",
        "        \"How do I reset my password?\",\n",
        "        \"My account was suspended without reason.\",\n",
        "        \"I want to close my account.\",\n",
        "        \"There is a problem with my account verification.\",\n",
        "        \"I cannot access premium features.\",\n",
        "        \"My account shows wrong order history.\",\n",
        "        \"I did not receive the account confirmation email.\",\n",
        "        \"Account login fails despite correct credentials.\",\n",
        "        \"I want to link my account to social media.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 2. Load sentence transformer model\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# 3. Compute averaged embeddings for each tag\n",
        "tag_names = []\n",
        "tag_embeddings = []\n",
        "\n",
        "for tag, examples in fixed_tags_examples.items():\n",
        "    embeddings = embedder.encode(examples)\n",
        "    avg_embedding = np.mean(embeddings, axis=0)\n",
        "    tag_names.append(tag)\n",
        "    tag_embeddings.append(avg_embedding)\n",
        "\n",
        "tag_embeddings = np.vstack(tag_embeddings).astype('float32')\n",
        "\n",
        "# 4. Build FAISS index\n",
        "dimension = tag_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 distance\n",
        "index.add(tag_embeddings)\n",
        "\n",
        "print(f\"FAISS index built with {index.ntotal} tags.\")\n",
        "\n",
        "# 5. Define function to find top-k matching tags for a transcript\n",
        "def tag_transcript(transcript, top_k=3):\n",
        "    transcript_emb = embedder.encode([transcript]).astype('float32')\n",
        "    distances, indices = index.search(transcript_emb, top_k)\n",
        "    results = []\n",
        "    for dist, idx in zip(distances[0], indices[0]):\n",
        "        tag = tag_names[idx]\n",
        "        score = 1 / (1 + dist)  # convert L2 dist to similarity-like score\n",
        "        results.append((tag, score))\n",
        "    return results\n",
        "\n",
        "# --- Example usage ---\n",
        "sample_text = \"Hello, this is Shriyank, I am talking to Flipkart. Yeah, my order hasn't been delivered for two days. No, I had already contacted the seller, but it has still not been delivered. Please look forward to the issues. Yes, yes.\"\n",
        "matches = tag_transcript(sample_text)\n",
        "\n",
        "print(\"Top matching tags:\")\n",
        "for tag, score in matches:\n",
        "    print(f\"- {tag} (score: {score:.4f})\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import streamlit as st\n",
        "import requests\n",
        "from pydub import AudioSegment\n",
        "import io\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "\n",
        "def tag_transcript(transcript, top_k=3):\n",
        "    transcript_emb = embedder.encode([transcript]).astype('float32')\n",
        "    distances, indices = index.search(transcript_emb, top_k)\n",
        "    results = []\n",
        "    for dist, idx in zip(distances[0], indices[0]):\n",
        "        tag = tag_names[idx]\n",
        "        score = 1 / (1 + dist)  # convert L2 dist to similarity-like score\n",
        "        results.append((tag, score))\n",
        "    return results\n",
        "\n",
        "# --- Sarvam AI STT Configuration ---\n",
        "SARVAM_AI_API_KEY = \"35215873-d423-44c0-89ea-5e2550ce057f\"\n",
        "API_URL = \"https://api.sarvam.ai/speech-to-text\"\n",
        "LANGUAGE_CODE = \"en-IN\"\n",
        "MODEL_NAME = \"saarika:v2\"\n",
        "\n",
        "# --- Load HuggingFace Sentiment Model ---\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "def map_sentiment(score, label):\n",
        "    if label.lower() == \"positive\":\n",
        "        if score >= 0.95:\n",
        "            return \"excellent\"\n",
        "        elif score >= 0.85:\n",
        "            return \"good\"\n",
        "        else:\n",
        "            return \"decent\"\n",
        "    elif label.lower() == \"negative\":\n",
        "        if score >= 0.95:\n",
        "            return \"horrible\"\n",
        "        elif score >= 0.85:\n",
        "            return \"very bad\"\n",
        "        else:\n",
        "            return \"bad\"\n",
        "    return \"neutral\"\n",
        "\n",
        "def chunk_text(text, max_length=512):\n",
        "    sentences = text.split(\". \")\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk) + len(sentence) < max_length:\n",
        "            current_chunk += sentence + \". \"\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \". \"\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "    return chunks\n",
        "\n",
        "def extract_sentiment(text, return_chunks=False):\n",
        "    if not text.strip():\n",
        "        return {\n",
        "            \"label\": \"neutral\",\n",
        "            \"original_label\": \"neutral\",\n",
        "            \"polarity\": 0.0\n",
        "        }\n",
        "\n",
        "    chunks = chunk_text(text)\n",
        "    results = sentiment_pipeline(chunks)\n",
        "\n",
        "    pos_scores = []\n",
        "    neg_scores = []\n",
        "    mapped_labels = []\n",
        "\n",
        "    for res in results:\n",
        "        label = res['label']\n",
        "        score = res['score']\n",
        "        mapped = map_sentiment(score, label)\n",
        "        mapped_labels.append(mapped)\n",
        "\n",
        "        if label.lower() == \"positive\":\n",
        "            pos_scores.append(score)\n",
        "        elif label.lower() == \"negative\":\n",
        "            neg_scores.append(score)\n",
        "\n",
        "    avg_pos = np.mean(pos_scores) if pos_scores else 0\n",
        "    avg_neg = np.mean(neg_scores) if neg_scores else 0\n",
        "\n",
        "    if avg_pos > avg_neg:\n",
        "        overall_label = \"positive\"\n",
        "        polarity = avg_pos\n",
        "    elif avg_neg > avg_pos:\n",
        "        overall_label = \"negative\"\n",
        "        polarity = avg_neg\n",
        "    else:\n",
        "        overall_label = \"neutral\"\n",
        "        polarity = 0.0\n",
        "\n",
        "    final_sentiment = map_sentiment(polarity, overall_label)\n",
        "\n",
        "    result = {\n",
        "        \"label\": final_sentiment,\n",
        "        \"original_label\": overall_label,\n",
        "        \"polarity\": polarity\n",
        "    }\n",
        "\n",
        "    if return_chunks:\n",
        "        result[\"chunk_sentiments\"] = [\n",
        "            {\n",
        "                \"text\": chunk,\n",
        "                \"raw\": res,\n",
        "                \"mapped_label\": map_sentiment(res['score'], res['label'])\n",
        "            }\n",
        "            for chunk, res in zip(chunks, results)\n",
        "        ]\n",
        "\n",
        "    return result\n",
        "\n",
        "# --- Transcription Handler ---\n",
        "def transcribe_audio(audio_bytes, file_type=\"mp3\"):\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format=file_type)\n",
        "        buffer = io.BytesIO()\n",
        "        audio.export(buffer, format=\"wav\")\n",
        "        buffer.seek(0)\n",
        "    except Exception as e:\n",
        "        st.error(f\" Audio conversion error: {e}\")\n",
        "        return None\n",
        "\n",
        "    headers = {\"api-subscription-key\": SARVAM_AI_API_KEY}\n",
        "    data = {\n",
        "        \"language_code\": LANGUAGE_CODE,\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"with_timestamps\": False\n",
        "    }\n",
        "    files = {\"file\": (\"audio.wav\", buffer, \"audio/wav\")}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(API_URL, headers=headers, data=data, files=files)\n",
        "        if response.status_code in [200, 201]:\n",
        "            return response.json().get(\"transcript\", \" No transcript found.\")\n",
        "        else:\n",
        "            st.error(f\"❌ API Error {response.status_code}: {response.text}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        st.error(f\"❌ Request failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Streamlit App Main ---\n",
        "def main():\n",
        "    st.set_page_config(page_title=\" Call Transcript Analyzer\", layout=\"wide\")\n",
        "    st.title(\" Audio Transcription + Call Transcript Analyzer\")\n",
        "    st.markdown(\"Upload `.wav` or `.mp3` files to transcribe and analyze the conversation.\")\n",
        "\n",
        "    uploaded_files = st.file_uploader(\" Upload Audio Files\", type=[\"wav\", \"mp3\"], accept_multiple_files=True)\n",
        "\n",
        "    if uploaded_files:\n",
        "        combined_transcript = \"\"\n",
        "        for audio_file in uploaded_files:\n",
        "            file_type = audio_file.name.split('.')[-1].lower()\n",
        "            st.audio(audio_file, format=f\"audio/{file_type}\")\n",
        "            st.info(f\"Transcribing `{audio_file.name}`...\")\n",
        "\n",
        "            audio_bytes = audio_file.read()\n",
        "            transcript = transcribe_audio(audio_bytes, file_type)\n",
        "\n",
        "            if transcript:\n",
        "                st.markdown(f\"**Transcript for `{audio_file.name}`:**\")\n",
        "                st.write(transcript)\n",
        "                combined_transcript += transcript + \"\\\\n\\\\n\"\n",
        "            else:\n",
        "                st.error(f\"Failed to transcribe `{audio_file.name}`\")\n",
        "\n",
        "        if combined_transcript.strip():\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"### Combined Transcript\")\n",
        "            st.text_area(\"Combined Transcript\", combined_transcript.strip(), height=250)\n",
        "\n",
        "            if st.button(\"Analyze Combined Transcript\"):\n",
        "                with st.spinner(\"Analyzing...\"):\n",
        "                    result = extract_sentiment(combined_transcript.strip(), return_chunks=True)\n",
        "                    tags = tag_transcript(combined_transcript.strip(), top_k=3)\n",
        "\n",
        "                st.success(\" Analysis Complete!\")\n",
        "\n",
        "                with st.expander(\" Overall Sentiment\"):\n",
        "                    st.write(f\"Label: **{result['label']}**\")\n",
        "                    st.write(f\"Polarity: {result['polarity']:.2f}\")\n",
        "\n",
        "                with st.expander(\" Detected Tags\"):\n",
        "                    for tag, score in tags:\n",
        "                        st.write(f\"- **{tag}** (Confidence: {score:.2f})\")\n",
        "\n",
        "                with st.expander(\" Chunk-Level Sentiment Breakdown\"):\n",
        "                    for i, chunk_data in enumerate(result.get(\"chunk_sentiments\", []), 1):\n",
        "                        st.markdown(f\"**Chunk {i}:** {chunk_data['mapped_label']} \"\n",
        "                                    f\"({chunk_data['raw']['label']} - {chunk_data['raw']['score']:.2f})\")\n",
        "                        st.caption(chunk_data[\"text\"])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Draln_v61y_J"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/zapp.py\", \"w\") as f:\n",
        "    f.write(streamlit_code)\n",
        "\n",
        "print(\"Streamlit app saved to /content/zapp.py\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-fj4fVlSREa",
        "outputId": "78322d36-494a-4a26-9c95-96fcb4d97733"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app saved to /content/zapp.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace with your actual token from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "ngrok.set_auth_token(\"2yHRNdhTQXM6sJYfD9PdF60D6e4_44nc9gXSyLiQsNbFmWWUh\")\n"
      ],
      "metadata": {
        "id": "OsBqWzU512U-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8qBVlUsZr_cn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AFTER RUNNING BELOW CELL YOU GET TWO LINKS TO DEPLOYED SITE OUT OF THOSE TWO SELECT  NgrokTunnel URL and then click visist site"
      ],
      "metadata": {
        "id": "pAWR8dW0ru4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Streamlit app in the background\n",
        "!streamlit run /content/zapp.py &>/content/logs.txt &\n",
        "\n",
        "# Wait briefly to allow app to start\n",
        "import time; time.sleep(3)\n",
        "\n",
        "# Expose the port using ngrok\n",
        "# Kill existing processes if rer\n",
        "\n",
        "# Run streamlit in background\n",
        "!streamlit run /content/zapp.py &> /content/logs.txt &\n",
        "\n",
        "# Create the tunnel (use \"http\" instead of \"port\")\n",
        "public_url = ngrok.connect(addr=\"8510\", proto=\"http\")\n",
        "print(f\" Public URL: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwjG_e7gKcKm",
        "outputId": "70ef7a4f-ef65-44e0-ee08-943123c0f4c2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Public URL: NgrokTunnel: \"https://3005-34-106-7-242.ngrok-free.app\" -> \"http://localhost:8510\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***!!!!!!!! *** RUN THE BELOW CEll ONLY WHEN YOU HAVE MORE THAN  3 STREAMLIT ADDRESES ACTIVE AND ERROR COMES THROUGH THE NGROK. AFTER RUNNING BELOW CELL RESTART THE SESSION AGAIN AND RUN ALL ABOVE CELLS EXCEPT THIS."
      ],
      "metadata": {
        "id": "a1kPqOZlq3Z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.kill()  #  This stops all running ngrok tunnels\n"
      ],
      "metadata": {
        "id": "NY9FaPgi-kia"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}